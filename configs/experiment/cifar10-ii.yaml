# @package _global_

# to execute this experiment run:
# python run.py experiment=example_full.yaml

defaults:
  - override /trainer: null # override trainer to null so it's not loaded from main config defaults...
  - override /model: null
  - override /datamodule: null
  - override /callbacks: null
  - override /logger: null
  - override /testmodules: null

# we override default configurations with nulls to prevent them from loading at all
# instead we define all modules and their paths directly in this config,
# so everything is stored in one place

seed: 12345

# TODO: not all operations are implemented as deterministic
deterministic: False

trainer:
  _target_: pytorch_lightning.Trainer
  gpus: 0
  min_epochs: 20
  max_epochs: 20
  limit_train_batches: 400
  #  gradient_clip_val: 0.5
  #  accumulate_grad_batches: 2
  weights_summary: null
  # resume_from_checkpoint: ${work_dir}/last.ckpt

model:
  _target_: src.models.IIModel
  lr: 0.00001
  weight_decay: 0.00005
  # pretrained weights?
  pretrained: null
  n_classes: 10
  n_embedding: 10
  backbone:
    # _target_: torchvision.models.resnet.wide_resnet101_2
    _target_: src.models.modules.wrn.WideResNet
    num_classes: 10
    widen_factor: 2
    depth: 40
    drop_rate: 0.3

datamodule:
  _target_: src.datamodules.cifar10_datamodule.CIFAR10DataModule
  data_dir: ${data_dir}
  batch_size: 256
  train_val_split: [ 45_000, 5_000 ]
  num_workers: 10
  pin_memory: True
  data_order_seed: null
  data_split_seed: null

testmodules:
  # define test cases
  test_vs_uniformnoise:
    _target_: src.datamodules.ood_datamodule.OODDataModule
    data_in:
      _target_: torchvision.datasets.CIFAR10
      root: ${data_dir}
      train: False
      download: True
    data_out:
      _target_: src.datamodules.datasets.noise.UniformNoise
      samples: 10000
      size: [32, 32, 3]
  test_vs_gaussiannoise:
    _target_: src.datamodules.ood_datamodule.OODDataModule
    data_in:
      _target_: torchvision.datasets.CIFAR10
      root: ${data_dir}
      train: False
      download: True
    data_out:
      _target_: src.datamodules.datasets.noise.GaussianNoise
      samples: 10000
      size: [32, 32, 3]

  test_vs_tinycrop:
    _target_: src.datamodules.ood_datamodule.OODDataModule
    data_in:
      _target_: torchvision.datasets.CIFAR10
      root: ${data_dir}
      train: False
      download: True
    data_out:
      _target_: src.datamodules.datasets.odin.TinyImageNetCrop
      root: ${data_dir}
      download: True
  test_vs_tinyresize:
    _target_: src.datamodules.ood_datamodule.OODDataModule
    data_in:
      _target_: torchvision.datasets.CIFAR10
      root: ${data_dir}
      train: False
      download: True
    data_out:
      _target_: src.datamodules.datasets.odin.TinyImageNetResize
      root: ${data_dir}
      download: True
  test_vs_lsuncrop:
    _target_: src.datamodules.ood_datamodule.OODDataModule
    data_in:
      _target_: torchvision.datasets.CIFAR10
      root: ${data_dir}
      train: False
      download: True
    data_out:
      _target_: src.datamodules.datasets.odin.LSUNCrop
      root: ${data_dir}
      download: True
  test_vs_lsunresize:
    _target_: src.datamodules.ood_datamodule.OODDataModule
    data_in:
      _target_: torchvision.datasets.CIFAR10
      root: ${data_dir}
      train: False
      download: True
    data_out:
      _target_: src.datamodules.datasets.odin.LSUNResize
      root: ${data_dir}
      download: True

callbacks:
  model_checkpoint:
    _target_: pytorch_lightning.callbacks.ModelCheckpoint
    monitor: "Accuracy/val" # name of the logged metric which determines when model is improving
    save_top_k: 1 # save k best models (determined by above metric)
    save_last: True # additionaly always save model from last epoch
    mode: "max" # can be "max" or "min"
    verbose: False
    dirpath: "checkpoints/"
    filename: "{epoch:02d}"
  early_stopping:
    _target_: pytorch_lightning.callbacks.EarlyStopping
    monitor: "Accuracy/val" # name of the logged metric which determines when model is improving
    patience: 100 # how many epochs of not improving until training stops
    mode: "max" # can be "max" or "min"
    min_delta: 0 # minimum change in the monitored metric needed to qualify as an improvement
  lr_monitor:
    _target_: pytorch_lightning.callbacks.LearningRateMonitor

  #########################
  softmax:
    _target_: src.callbacks.softmax.SoftmaxThresholding
    use_in_val: True
    use_in_test: True
  energy:
    _target_: src.callbacks.energy.EnergyBased
    temperature: 1
    use_in_val: True
    use_in_test: True
  mcd:
    _target_: src.callbacks.mcd.MonteCarloDropout
    num_classes: 10
    rounds: 30
    use_in_val: False
    use_in_test: False
#  openmax:
#    _target_: src.callbacks.openmax.OpenMax
#    tailsize: 3
#    alpha: 3
#    euclid_weight: 0
#    use_in_val: False
#    use_in_test: True
  odin:
    _target_: src.callbacks.odin.ODIN
    eps: 0.02
    t: 1000
    use_in_val: False
    use_in_test: True
  tscaling:
    _target_: src.callbacks.tscaling.TemperatureScaling
    temperature: 1000
    use_in_val: True
    use_in_test: True


logger:
  # https://www.tensorflow.org/tensorboard/
  tensorboard:
    _target_: pytorch_lightning.loggers.tensorboard.TensorBoardLogger
    save_dir: "."
    name: "tb"
    version: null
    log_graph: False
    default_hp_metric: True
    prefix: ""
  csv_logger:
    save_dir: "."
